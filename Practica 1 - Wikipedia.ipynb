{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El primer paso es importar los paquetes necesarios\n",
    "import builtwith\n",
    "import whois\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos la url de la pagina \n",
    "url='https://es.wikipedia.org/wiki/Anexo:Pa%C3%ADses_y_territorios_dependientes_por_poblaci%C3%B3n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La pagina al cual extraermos la información es Mercado libre Colombia. \n",
    "Al revisar el archivo robots.txt. nos damos cuenta que se excluyen tres directorios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conocer la tecnología utilizada para diseñar la pagina web\n",
    "builtwith.builtwith('https://es.wikipedia.org/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conocer el propietario de la página web\n",
    "import whois\n",
    "print (whois.whois('https://es.wikipedia.org/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cronstuimos una función automatizada que extrae el html de un link\n",
    "def obtener_html(link):\n",
    "    html =urlopen(link)\n",
    "    soup=BeautifulSoup(html, 'html.parser')\n",
    "    return soup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraemos el html utilizando la función \n",
    "pagina=obtener_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buscamos todos los elementos identificados como una tabla en el html\n",
    "tablas = pagina.find_all('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encontramos que en la pagina hay 2 tablas. \n",
    "len(tablas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizamos la funcion pretiffy() para hacer mpas legible el html de la tabla de nuestro interés, en este caso es la primera tabla. \n",
    "print(tablas[0].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos HTML del modulo IPython.display y usela para ver la tabla de una manera más bonita\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(tablas[0].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraemos la tabla de la población\n",
    "tabla_poblacion=pagina.find('table',{'class':\"wikitable sortable\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraemos las filas de la tabal de población\n",
    "filas=tabla_poblacion.find_all('tr')\n",
    "#las filas de las tablas están identificados por tr o \\tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paises=[]\n",
    "proyeccion_2021=[]\n",
    "porcentaje=[]\n",
    "CMA=[] #Cambio Medio Anual\n",
    "CAAP=[] #Cambio Absoluto Anual Promedio\n",
    "PCMATA=[] #Porcentaje del Cambio Medio Absoluto Total Anual\n",
    "AED=[] #Años para Eventual Duplicación\n",
    "CMR=[] #Censo Más Reciente\n",
    "\n",
    "#Construimos un loop para extraer esta información para todas las filas\n",
    "for row in filas:\n",
    "    celdas=row.find_all('td') #las celdas que tienen los datos se identifican por 'td' '\\td'\n",
    "    if len(celdas)>1:\n",
    "        paises.append(celdas[1].get_text().replace('\\xa0',\" \"))\n",
    "        proyeccion_2021.append(celdas[2].get_text())\n",
    "        porcentaje.append(celdas[3].get_text())\n",
    "        CMA.append(celdas[4].get_text())\n",
    "        CAAP.append(celdas[5].get_text())\n",
    "        PCMATA.append(celdas[6].get_text())\n",
    "        AED.append(celdas[7].get_text())\n",
    "        CMR.append(celdas[8].get_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construimos un DataFrame para almacenar la información extraida de la pagina\n",
    "df_paises=pd.DataFrame({'pais':paises, 'proyeccion_2021':proyeccion_2021, \n",
    "                        'porcentaje':porcentaje, 'CMA':CMA, 'CAAP':CAAP,\n",
    "                       'PCMATA':PCMATA, 'AED':AED, 'CMR':CMR})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paises.to_csv('paises_wikipedia.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
